{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::603012210694:role/service-role/AmazonSageMaker-ExecutionRole-20210304T123661\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you wan't to run locally on laptop\n",
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "def resolve_sm_role():\n",
    "    client = boto3.client('iam', region_name=region)\n",
    "    response_roles = client.list_roles(\n",
    "        PathPrefix='/',\n",
    "        # Marker='string',\n",
    "        MaxItems=999\n",
    "    )\n",
    "    for role in response_roles['Roles']:\n",
    "        if role['RoleName'].startswith('AmazonSageMaker-ExecutionRole-'):\n",
    "            #print('Resolved SageMaker IAM Role to: ' + str(role))\n",
    "            return role['Arn']\n",
    "    raise Exception('Could not resolve what should be the SageMaker role to be used')\n",
    "\n",
    "role = resolve_sm_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Step\n",
    "if you have run last pracice you don't need to run this cell\n",
    "Because there we already prepare the data and upload it in s3\n",
    "if you did't run prevouse code or have deleted that s3 bucket\n",
    "You should run this cell\n",
    "If you wan't to know about these command see previos example\n",
    "\n",
    "Im not going to run below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "from sklearn.datasets import load_boston\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "data = boston\n",
    "df = DataFrame(np.concatenate((boston.data, boston.target.reshape(-1, 1)), axis=1), \n",
    "                            columns=np.concatenate((boston.feature_names, [\"MEDV\"])))\n",
    "\n",
    "del df['B']\n",
    "\n",
    "df = pd.concat([df['MEDV'],df.drop(['MEDV'], axis=1)],axis=1)\n",
    "\n",
    "# spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_dataset, validation_dataset = train_test_split(df, test_size=0.1)\n",
    "\n",
    "training_dataset.to_csv('training_dataset.csv', index=False, header=False)\n",
    "validation_dataset.to_csv('validation_dataset.csv', index=False, header=False)\n",
    "\n",
    "# Uploading data\n",
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "prefix = 'boston-housing'\n",
    "training_data_path = sess.upload_data(path='training_dataset.csv', key_prefix=prefix + '/input/training')\n",
    "validation_data_path = sess.upload_data(path='validation_dataset.csv', key_prefix=prefix + '/input/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with XGBoost\n",
    "Let's train a model on the Boston Housing dataset with the XGBoost algorithm\n",
    "( https://github.com/dmlc/xgboost ). As we will see in Chapter 7, Using Built-in\n",
    "Frameworks, SageMaker also supports XGBoost scripts:\n",
    "\n",
    "1. We reuse the dataset preparation steps from the previous examples.\n",
    "\n",
    "2. We find the name of the XGBoost container. As several versions are supported,\n",
    "\n",
    "we select the latest one (1.0-1 at the time of writing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "region = boto3.Session().region_name\n",
    "container = image_uris.retrieve('xgboost', region, version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from previous example\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'boston-housing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We configure the Estimator function. The code is strictly identical to the one used with LinearLearner :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = Estimator(container,\n",
    "                        role=role,#sagemaker.get_execution_role(),\n",
    "                        instance_count=1,\n",
    "                        instance_type='ml.m4.xlarge',#'ml.m5.large',\n",
    "                        output_path='s3://{}/{}/output'.format(bucket,\n",
    "                        prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Taking a look at the hyperparameters ( https://docs.aws.amazon.com/\n",
    "sagemaker/latest/dg/xgboost_hyperparameters.html ), we see that\n",
    "the only required one is num_round . As it's not obvious which value to set,\n",
    "we'll go for a large value, and we'll also define the early_stopping_rounds\n",
    "parameter in order to avoid overfitting. Of course, we need to set the objective for\n",
    "a regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.set_hyperparameters(\n",
    "            objective='reg:linear',\n",
    "            num_round=200,\n",
    "            early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We define the training input, just like in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have these CSV in Current directory this code will not work\n",
    "training_data_path = sess.upload_data(path='training_dataset.csv', key_prefix=prefix + '/input/training')\n",
    "validation_data_path = sess.upload_data(path='validation_dataset.csv', key_prefix=prefix + '/input/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_channel = sagemaker.TrainingInput(\n",
    "                        s3_data=training_data_path,\n",
    "                        content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_channel = sagemaker.TrainingInput(\n",
    "                                    s3_data=validation_data_path,\n",
    "                                    content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We then launch the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-28 14:04:06 Starting - Starting the training job...\n",
      "2021-03-28 14:04:08 Starting - Launching requested ML instancesProfilerReport-1616940245: InProgress\n",
      "......\n",
      "2021-03-28 14:05:41 Starting - Preparing the instances for training......\n",
      "2021-03-28 14:06:55 Downloading - Downloading input data...\n",
      "2021-03-28 14:07:22 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-03-28:14:07:43:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-03-28:14:07:43:INFO] File size need to be processed in the node: 0.03mb. Available memory size in the node: 8435.86mb\u001b[0m\n",
      "\u001b[34m[2021-03-28:14:07:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:07:43] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:07:43] 455x12 matrix with 5460 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-03-28:14:07:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:07:43] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:07:43] 51x12 matrix with 612 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:16.7275#011validation-rmse:20.3457\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:12.0831#011validation-rmse:15.213\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:8.81837#011validation-rmse:11.3559\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:6.49944#011validation-rmse:8.58195\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:4.87212#011validation-rmse:6.79281\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:3.73904#011validation-rmse:5.47942\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.94954#011validation-rmse:4.64373\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.40868#011validation-rmse:3.95109\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:2.02153#011validation-rmse:3.57355\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:1.76986#011validation-rmse:3.34715\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:1.60156#011validation-rmse:3.14539\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:1.4816#011validation-rmse:3.0888\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:1.3821#011validation-rmse:2.97919\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.29248#011validation-rmse:2.85502\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:1.23873#011validation-rmse:2.84316\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:1.16912#011validation-rmse:2.77859\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:1.13496#011validation-rmse:2.74897\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:1.10575#011validation-rmse:2.73754\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:1.0131#011validation-rmse:2.70236\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.94691#011validation-rmse:2.64815\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.910793#011validation-rmse:2.63966\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.828372#011validation-rmse:2.64036\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.767059#011validation-rmse:2.62017\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.735427#011validation-rmse:2.6321\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.707213#011validation-rmse:2.61384\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.655546#011validation-rmse:2.5978\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.621144#011validation-rmse:2.58594\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.594614#011validation-rmse:2.55756\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.575982#011validation-rmse:2.54686\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.557207#011validation-rmse:2.54286\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.537709#011validation-rmse:2.53486\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.51693#011validation-rmse:2.51651\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.501834#011validation-rmse:2.51624\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.484507#011validation-rmse:2.51633\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.462167#011validation-rmse:2.52373\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.449289#011validation-rmse:2.52408\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.436559#011validation-rmse:2.5198\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.421176#011validation-rmse:2.50801\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.412211#011validation-rmse:2.50874\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.400536#011validation-rmse:2.49828\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.383769#011validation-rmse:2.49165\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.377143#011validation-rmse:2.49616\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.370018#011validation-rmse:2.5\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.349587#011validation-rmse:2.50139\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.318024#011validation-rmse:2.50093\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.309488#011validation-rmse:2.49528\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.304794#011validation-rmse:2.49162\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.296831#011validation-rmse:2.49042\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.291502#011validation-rmse:2.49032\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.287479#011validation-rmse:2.49266\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.272913#011validation-rmse:2.49719\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.259941#011validation-rmse:2.49797\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.243147#011validation-rmse:2.49005\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.237335#011validation-rmse:2.4927\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.226201#011validation-rmse:2.5021\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.211238#011validation-rmse:2.5007\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.204145#011validation-rmse:2.49894\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.197113#011validation-rmse:2.49994\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.189869#011validation-rmse:2.50138\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.187475#011validation-rmse:2.50012\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.175195#011validation-rmse:2.50231\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.165603#011validation-rmse:2.49904\u001b[0m\n",
      "\u001b[34m[14:07:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.158975#011validation-rmse:2.5013\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.243147#011validation-rmse:2.49005\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-28 14:08:02 Uploading - Uploading generated training model\n",
      "2021-03-28 14:08:02 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit({'train': training_data_channel,\n",
    "                    'validation': validation_data_channel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The job only ran for 22 rounds, meaning that early stopping was triggered. Looking\n",
    "at the training log, we see that round #12 was actually the best one, with a root\n",
    "mean square error (RMSE) of 2.43126:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Deploying still takes one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, gmtime\n",
    "timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "endpoint_name = 'xgb-demo'+'-'+timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_estimator.deploy(\n",
    "                endpoint_name=endpoint_name,\n",
    "                initial_instance_count=1,\n",
    "                instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Once the model is deployed, we used the predict() API again to send\n",
    "it a CSV sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = '0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,4.98'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['23.949708938598633']]\n"
     ]
    }
   ],
   "source": [
    "#xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "xgb_predictor.deserializer = sagemaker.deserializers.CSVDeserializer()\n",
    "\n",
    "response = xgb_predictor.predict(test_sample)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result tells us that this house should cost $23,754.\n",
    "[['23.73023223876953']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Finally, we delete the endpoint when we're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAGEMAKER",
   "language": "python",
   "name": "sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
